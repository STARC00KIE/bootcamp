{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìˆ˜ì • í¬ì¸íŠ¸\n",
    "1. ë°ì´í„° ì¦ê°• ì¶”ê°€, ê¸°ì¡´ì—ëŠ” ì •ê·œí™”ë§Œ ìˆì—ˆìŒ, resnet18 ë°±ë³¸ ì‚¬ìš©\n",
    "2. Early Stopping, resnet18 ë°±ë³¸ ì‚¬ìš©\n",
    "3. ConvNeXt-Tinyë¡œ ë°±ë³¸ ë³€ê²½\n",
    "4. AMP ì ìš©, í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ ë¡œìŠ¤ì— ë¼ë²¨ ìŠ¤ë¬´ì‹± 0.1 ì ìš©, ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ 384 ì ìš©ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\os415\\.conda\\envs\\hai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'IMG_SIZE': 224, # ëª¨ë¸ì— ì…ë ¥ë˜ëŠ” ì´ë¯¸ì§€ í¬ê¸°\n",
    "# 'BATCH_SIZE': 64, # í•œ ë²ˆì— ëª¨ë¸ì— ë„£ëŠ” ì´ë¯¸ì§€ ìˆ˜\n",
    "# 'EPOCHS': 50, # ì „ì²´ ë°ì´í„°ë¥¼ ëª‡ ë²ˆ ë°˜ë³µ í•™ìŠµí• ì§€\n",
    "#'LEARNING_RATE': ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ì •ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•™ìŠµë¥ \n",
    "# 'SEED' : ë¬´ì‘ìœ„ ìš”ì†Œë“¤ì„ ê³ ì •í•˜ì—¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì¬í˜„ ê°€ëŠ¥í•˜ê²Œ í•¨\n",
    "# \n",
    "CFG = {\n",
    "    'IMG_SIZE': 384,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë”¥ëŸ¬ë‹ í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ë¬´ì‘ìœ„ì„±ì´ ë§ì´ ê°œì…ëœ\n",
    "# ë¬´ì‘ìœ„ì„±: ë°ì´í„° ë¡œë”© ìˆœì„œ, ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, dropout, ë°ì´í„° ì¦ê°•, gpu ì—°ì‚°ì˜ ë¹„ê²°ì •ì„±\n",
    "# ê·¸ë ˆì„œ ì‹œë“œë¥¼ ê³ ì •í•˜ì§€ ì•ˆìœ¼ë©´ ë§¤ë²ˆ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ê²°ê³¼ê°€ ë‹¬ë¼ì§\n",
    "# ë™ì¼í•œ ê²°ê³¼ê°€ ì¬í˜„ë˜ë„ë¡ í•˜ê¸° ìœ„í•œ ì„¤ì •ì´ seed_everyting í•¨ìˆ˜ìˆ˜\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed ê³ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # í…ŒìŠ¤íŠ¸ì…‹: ë¼ë²¨ ì—†ì´ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # í•™ìŠµì…‹: í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ì—ì„œ ë¼ë²¨ ì¶”ì¶œ\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = np.array(Image.open(img_path).convert('RGB'))\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = np.array(Image.open(img_path).convert('RGB'))\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './data/train'\n",
    "test_root = './data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\os415\\.conda\\envs\\hai\\Lib\\site-packages\\albumentations\\core\\validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\os415\\AppData\\Local\\Temp\\ipykernel_5592\\2295189183.py:28: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=2,          # ìµœëŒ€ 2ê°œ ì˜ì—­ ì œê±°\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ ë°ì´í„°ì— ì ìš©í•  ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸\n",
    "train_transform = A.Compose([\n",
    "    # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ê³ ì •\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "\n",
    "    # ì¢Œìš° ë°˜ì „: ì°¨ëŸ‰ì´ ì¢Œìš° ì–´ëŠ ë°©í–¥ì„ í–¥í•´ ìˆì–´ë„ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "\n",
    "    # ë°ê¸°/ëŒ€ë¹„ ëœë¤ ì¡°ì ˆ: ì•¼ì™¸ ì´¬ì˜ ì‹œ ì¡°ëª… ì°¨ì´ë¥¼ ë°˜ì˜\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "\n",
    "    # ìƒ‰ì¡°(Hue), ì±„ë„(Saturation), ëª…ë„(Value) ë³€ê²½: ìƒ‰ìƒì— ëœ ë¯¼ê°í•˜ê²Œ\n",
    "    A.HueSaturationValue(p=0.2),\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì´ë™, í™•ëŒ€/ì¶•ì†Œ, íšŒì „: ë‹¤ì–‘í•œ ì´¬ì˜ ê°ë„ ë° ìœ„ì¹˜ ëŒ€ì‘\n",
    "    A.ShiftScaleRotate(shift_limit=0.05,   # ìµœëŒ€ Â±5% ì´ë™\n",
    "                       scale_limit=0.05,   # ìµœëŒ€ Â±5% í™•ëŒ€/ì¶•ì†Œ\n",
    "                       rotate_limit=15,    # ìµœëŒ€ Â±15ë„ íšŒì „\n",
    "                       p=0.5),\n",
    "\n",
    "    # ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€: ìì—°ê´‘ í™˜ê²½ì—ì„œì˜ ì´¬ì˜ ìƒí™©ì„ ë°˜ì˜\n",
    "    A.RandomShadow(p=0.2),\n",
    "\n",
    "    # RGB ì±„ë„ë³„ ìƒ‰ìƒ ì´ë™: ë‹¤ì–‘í•œ ì¹´ë©”ë¼ í™˜ê²½, í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤ ì°¨ì´ ëŒ€ì‘\n",
    "    A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.2),\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì¼ë¶€ë¶„ì„ ë¬´ì‘ìœ„ë¡œ ì§€ìš°ê¸° (ì¼ë¶€ ê°€ë¦¼ ìƒí™©ì„ ë°˜ì˜)\n",
    "    A.CoarseDropout(max_holes=2,          # ìµœëŒ€ 2ê°œ ì˜ì—­ ì œê±°\n",
    "                    max_height=16, \n",
    "                    max_width=16, \n",
    "                    p=0.3),\n",
    "\n",
    "    # í”½ì…€ê°’ì„ ì •ê·œí™” (ImageNet ì‚¬ì „í•™ìŠµ ëª¨ë¸ ê¸°ì¤€ í‰ê· /í‘œì¤€í¸ì°¨)\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "    # numpy ì´ë¯¸ì§€ â†’ PyTorch Tensor ë³€í™˜\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì´ë¯¸ì§€ ìˆ˜: 33137\n",
      "train ì´ë¯¸ì§€ ìˆ˜: 26509, valid ì´ë¯¸ì§€ ìˆ˜: 6628\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform ê°ê° ì ìš©\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train ì´ë¯¸ì§€ ìˆ˜: {len(train_dataset)}, valid ì´ë¯¸ì§€ ìˆ˜: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name: str, num_classes: int):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)  # ë¶„ë¥˜ê¸° ì œê±°\n",
    "\n",
    "        # ìë™ in_features ì¶”ì¶œ\n",
    "        try:\n",
    "            in_features = self.backbone.num_features  # timm ê³µí†µ ì†ì„±\n",
    "        except:\n",
    "            raise ValueError(f\"Could not find in_features for model {model_name}\")\n",
    "\n",
    "        # pooling ì—¬ë¶€ ê²°ì • (ConvNeXt ê°™ì€ ê²½ìš° í•„ìš”)\n",
    "        self.needs_pooling = hasattr(self.backbone, 'head') and isinstance(self.backbone.head, nn.Identity) is False\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1)) if self._is_2d_output() else None\n",
    "\n",
    "        self.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def _is_2d_output(self):\n",
    "        # ConvNeXt, EfficientNet ë“±ì€ (B, C, H, W)ë¡œ ì¶œë ¥ë¨ â†’ AdaptiveAvgPool í•„ìš”\n",
    "        example_input = torch.randn(1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            output = self.backbone(example_input)\n",
    "        return output.dim() == 4\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        if self.pool:\n",
    "            x = self.pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# resnet18, 1ë²ˆê³¼ 2ë²ˆ\\nclass BaseModel(nn.Module):\\n    def __init__(self, num_classes):\\n        super(BaseModel, self).__init__()\\n        self.backbone = models.resnet18(pretrained=True)  # ResNet18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\\n        self.feature_dim = self.backbone.fc.in_features \\n        self.backbone.fc = nn.Identity()  # feature extractorë¡œë§Œ ì‚¬ìš©\\n        self.head = nn.Linear(self.feature_dim, num_classes)  # ë¶„ë¥˜ê¸°\\n\\n    def forward(self, x):\\n        x = self.backbone(x)       \\n        x = self.head(x) \\n        return x\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# resnet18, 1ë²ˆê³¼ 2ë²ˆ\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=True)  # ResNet18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractorë¡œë§Œ ì‚¬ìš©\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # ë¶„ë¥˜ê¸°\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\os415\\.conda\\envs\\hai\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\os415\\.cache\\huggingface\\hub\\models--timm--efficientnetv2_rw_s.ra2_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\os415\\AppData\\Local\\Temp\\ipykernel_5592\\2869195272.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "[Epoch 1/50] Training:   0%|          | 0/415 [00:00<?, ?it/s]C:\\Users\\os415\\AppData\\Local\\Temp\\ipykernel_5592\\2869195272.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # float16 ì—°ì‚°\n",
      "[Epoch 1/50] Training:   5%|â–Œ         | 22/415 [00:14<03:54,  1.67it/s]"
     ]
    }
   ],
   "source": [
    "model = BaseModel(model_name='ConvNeXt-Tiny', num_classes=len(class_names)).to(device)\n",
    "best_logloss = float('inf')\n",
    "# ì¶”ê°€: Early Stoppingì„ ìœ„í•œ ë³€ìˆ˜\n",
    "patience = 5  # ê°œì„  ì—†ì„ ë•Œ ëª‡ epochê¹Œì§€ ê¸°ë‹¤ë¦´ì§€\n",
    "counter = 0   # í˜„ì¬ê¹Œì§€ ê°œì„ ë˜ì§€ ì•Šì€ íšŸìˆ˜\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ëŸ¬\n",
    "scaler = GradScaler()\n",
    "\n",
    "# í•™ìŠµ ë° ê²€ì¦ ë£¨í”„\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n",
    "\n",
    "    # Best model ì €ì¥\n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        torch.save(model.state_dict(), f'best_model.pth')\n",
    "        print(f\"ğŸ“¦ Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")\n",
    "        counter = 0  # ì„±ëŠ¥ ê°œì„ ë˜ì—ˆìœ¼ë¯€ë¡œ ì´ˆê¸°í™”\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"âš ï¸ No improvement for {counter} epoch(s).\")\n",
    "        if counter >= patience:\n",
    "            print(f\"â¹ Early stopping triggered at epoch {epoch+1}\")\n",
    "            break  # í•™ìŠµ ì¤‘ë‹¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\n",
    "model = BaseModel(model_name='ConvNeXt-Tiny', num_classes=len(class_names))\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "# ì¶”ë¡ \n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        # ê° ë°°ì¹˜ì˜ í™•ë¥ ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        for prob in probs.cpu():  # prob: (num_classes,)\n",
    "            result = {\n",
    "                class_names[i]: prob[i].item()\n",
    "                for i in range(len(class_names))\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "pred = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./result/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('./result/submission_04.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
