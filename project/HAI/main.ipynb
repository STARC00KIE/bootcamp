{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìˆ˜ì • í¬ì¸íŠ¸\n",
    "1. ë°ì´í„° ì¦ê°• ì¶”ê°€, ê¸°ì¡´ì—ëŠ” ì •ê·œí™”ë§Œ ìˆì—ˆìŒ\n",
    "2. Early Stopping ì¶”ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed ê³ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # í…ŒìŠ¤íŠ¸ì…‹: ë¼ë²¨ ì—†ì´ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # í•™ìŠµì…‹: í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ì—ì„œ ë¼ë²¨ ì¶”ì¶œ\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = np.array(Image.open(img_path).convert('RGB'))\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = np.array(Image.open(img_path).convert('RGB'))\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './data/train'\n",
    "test_root = './data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\albumentations\\core\\validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10848\\2295189183.py:28: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=2,          # ìµœëŒ€ 2ê°œ ì˜ì—­ ì œê±°\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ ë°ì´í„°ì— ì ìš©í•  ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸\n",
    "train_transform = A.Compose([\n",
    "    # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ê³ ì •\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "\n",
    "    # ì¢Œìš° ë°˜ì „: ì°¨ëŸ‰ì´ ì¢Œìš° ì–´ëŠ ë°©í–¥ì„ í–¥í•´ ìˆì–´ë„ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "\n",
    "    # ë°ê¸°/ëŒ€ë¹„ ëœë¤ ì¡°ì ˆ: ì•¼ì™¸ ì´¬ì˜ ì‹œ ì¡°ëª… ì°¨ì´ë¥¼ ë°˜ì˜\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "\n",
    "    # ìƒ‰ì¡°(Hue), ì±„ë„(Saturation), ëª…ë„(Value) ë³€ê²½: ìƒ‰ìƒì— ëœ ë¯¼ê°í•˜ê²Œ\n",
    "    A.HueSaturationValue(p=0.2),\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì´ë™, í™•ëŒ€/ì¶•ì†Œ, íšŒì „: ë‹¤ì–‘í•œ ì´¬ì˜ ê°ë„ ë° ìœ„ì¹˜ ëŒ€ì‘\n",
    "    A.ShiftScaleRotate(shift_limit=0.05,   # ìµœëŒ€ Â±5% ì´ë™\n",
    "                       scale_limit=0.05,   # ìµœëŒ€ Â±5% í™•ëŒ€/ì¶•ì†Œ\n",
    "                       rotate_limit=15,    # ìµœëŒ€ Â±15ë„ íšŒì „\n",
    "                       p=0.5),\n",
    "\n",
    "    # ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€: ìì—°ê´‘ í™˜ê²½ì—ì„œì˜ ì´¬ì˜ ìƒí™©ì„ ë°˜ì˜\n",
    "    A.RandomShadow(p=0.2),\n",
    "\n",
    "    # RGB ì±„ë„ë³„ ìƒ‰ìƒ ì´ë™: ë‹¤ì–‘í•œ ì¹´ë©”ë¼ í™˜ê²½, í™”ì´íŠ¸ë°¸ëŸ°ìŠ¤ ì°¨ì´ ëŒ€ì‘\n",
    "    A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.2),\n",
    "\n",
    "    # ì´ë¯¸ì§€ ì¼ë¶€ë¶„ì„ ë¬´ì‘ìœ„ë¡œ ì§€ìš°ê¸° (ì¼ë¶€ ê°€ë¦¼ ìƒí™©ì„ ë°˜ì˜)\n",
    "    A.CoarseDropout(max_holes=2,          # ìµœëŒ€ 2ê°œ ì˜ì—­ ì œê±°\n",
    "                    max_height=16, \n",
    "                    max_width=16, \n",
    "                    p=0.3),\n",
    "\n",
    "    # í”½ì…€ê°’ì„ ì •ê·œí™” (ImageNet ì‚¬ì „í•™ìŠµ ëª¨ë¸ ê¸°ì¤€ í‰ê· /í‘œì¤€í¸ì°¨)\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "    # numpy ì´ë¯¸ì§€ â†’ PyTorch Tensor ë³€í™˜\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì´ë¯¸ì§€ ìˆ˜: 33137\n",
      "train ì´ë¯¸ì§€ ìˆ˜: 26509, valid ì´ë¯¸ì§€ ìˆ˜: 6628\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform ê°ê° ì ìš©\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train ì´ë¯¸ì§€ ìˆ˜: {len(train_dataset)}, valid ì´ë¯¸ì§€ ìˆ˜: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=True)  # ResNet18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractorë¡œë§Œ ì‚¬ìš©\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # ë¶„ë¥˜ê¸°\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[Epoch 1/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:19<00:00,  1.60it/s]\n",
      "[Epoch 1/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:41<00:00,  2.53it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 4.6025 || Valid Loss : 2.7474 | Valid Accuracy : 58.3283%\n",
      "ğŸ“¦ Best model saved at epoch 1 (logloss: 2.7463)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:44<00:00,  1.46it/s]\n",
      "[Epoch 2/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:41<00:00,  2.52it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.9825 || Valid Loss : 1.0552 | Valid Accuracy : 81.6083%\n",
      "ğŸ“¦ Best model saved at epoch 2 (logloss: 1.0550)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:34<00:00,  1.51it/s]\n",
      "[Epoch 3/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:35<00:00,  2.93it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.8596 || Valid Loss : 0.5862 | Valid Accuracy : 88.2317%\n",
      "ğŸ“¦ Best model saved at epoch 3 (logloss: 0.5864)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:20<00:00,  1.59it/s]\n",
      "[Epoch 4/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:34<00:00,  2.99it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.4807 || Valid Loss : 0.3893 | Valid Accuracy : 90.8117%\n",
      "ğŸ“¦ Best model saved at epoch 4 (logloss: 0.3892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:20<00:00,  1.59it/s]\n",
      "[Epoch 5/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:34<00:00,  2.99it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.3137 || Valid Loss : 0.2958 | Valid Accuracy : 92.1696%\n",
      "ğŸ“¦ Best model saved at epoch 5 (logloss: 0.2957)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:19<00:00,  1.60it/s]\n",
      "[Epoch 6/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:34<00:00,  2.99it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.2280 || Valid Loss : 0.2513 | Valid Accuracy : 92.7731%\n",
      "ğŸ“¦ Best model saved at epoch 6 (logloss: 0.2517)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:20<00:00,  1.60it/s]\n",
      "[Epoch 7/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:34<00:00,  2.98it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1701 || Valid Loss : 0.2405 | Valid Accuracy : 93.1804%\n",
      "ğŸ“¦ Best model saved at epoch 7 (logloss: 0.2408)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [25:28<00:00,  3.68s/it]    \n",
      "[Epoch 8/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:42<00:00,  2.42it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1421 || Valid Loss : 0.2231 | Valid Accuracy : 93.5124%\n",
      "ğŸ“¦ Best model saved at epoch 8 (logloss: 0.2235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:35<00:00,  1.51it/s]\n",
      "[Epoch 9/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:36<00:00,  2.87it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1219 || Valid Loss : 0.2125 | Valid Accuracy : 94.1008%\n",
      "ğŸ“¦ Best model saved at epoch 9 (logloss: 0.2126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:20<00:00,  1.59it/s]\n",
      "[Epoch 10/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:35<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1082 || Valid Loss : 0.1944 | Valid Accuracy : 94.1762%\n",
      "ğŸ“¦ Best model saved at epoch 10 (logloss: 0.1948)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(num_classes=len(class_names)).to(device)\n",
    "best_logloss = float('inf')\n",
    "# ì¶”ê°€: Early Stoppingì„ ìœ„í•œ ë³€ìˆ˜\n",
    "patience = 5  # ê°œì„  ì—†ì„ ë•Œ ëª‡ epochê¹Œì§€ ê¸°ë‹¤ë¦´ì§€\n",
    "counter = 0   # í˜„ì¬ê¹Œì§€ ê°œì„ ë˜ì§€ ì•Šì€ íšŸìˆ˜\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "# í•™ìŠµ ë° ê²€ì¦ ë£¨í”„\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n",
    "\n",
    "    # Best model ì €ì¥\n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        torch.save(model.state_dict(), f'best_model.pth')\n",
    "        print(f\"ğŸ“¦ Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")\n",
    "        counter = 0  # ì„±ëŠ¥ ê°œì„ ë˜ì—ˆìœ¼ë¯€ë¡œ ì´ˆê¸°í™”\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"âš ï¸ No improvement for {counter} epoch(s).\")\n",
    "        if counter >= patience:\n",
    "            print(f\"â¹ Early stopping triggered at epoch {epoch+1}\")\n",
    "            break  # í•™ìŠµ ì¤‘ë‹¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\n",
    "model = BaseModel(num_classes=len(class_names))\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "# ì¶”ë¡ \n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        # ê° ë°°ì¹˜ì˜ í™•ë¥ ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        for prob in probs.cpu():  # prob: (num_classes,)\n",
    "            result = {\n",
    "                class_names[i]: prob[i].item()\n",
    "                for i in range(len(class_names))\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "pred = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./result/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('./result/submission_02.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
