{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수정 포인트\n",
    "1. 데이터 증강 추가, 기존에는 정규화만 있었음\n",
    "2. Early Stopping 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "\n",
    "        if is_test:\n",
    "            # 테스트셋: 라벨 없이 이미지 경로만 저장\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith(('.jpg')):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            # 학습셋: 클래스별 폴더 구조에서 라벨 추출\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith(('.jpg')):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = np.array(Image.open(img_path).convert('RGB'))\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = np.array(Image.open(img_path).convert('RGB'))\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './data/train'\n",
    "test_root = './data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\albumentations\\core\\validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10848\\2295189183.py:28: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=2,          # 최대 2개 영역 제거\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터에 적용할 데이터 증강 파이프라인\n",
    "train_transform = A.Compose([\n",
    "    # 이미지 크기를 모델 입력 크기에 맞게 고정\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "\n",
    "    # 좌우 반전: 차량이 좌우 어느 방향을 향해 있어도 학습 가능하도록\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "\n",
    "    # 밝기/대비 랜덤 조절: 야외 촬영 시 조명 차이를 반영\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "\n",
    "    # 색조(Hue), 채도(Saturation), 명도(Value) 변경: 색상에 덜 민감하게\n",
    "    A.HueSaturationValue(p=0.2),\n",
    "\n",
    "    # 이미지 이동, 확대/축소, 회전: 다양한 촬영 각도 및 위치 대응\n",
    "    A.ShiftScaleRotate(shift_limit=0.05,   # 최대 ±5% 이동\n",
    "                       scale_limit=0.05,   # 최대 ±5% 확대/축소\n",
    "                       rotate_limit=15,    # 최대 ±15도 회전\n",
    "                       p=0.5),\n",
    "\n",
    "    # 그림자 효과 추가: 자연광 환경에서의 촬영 상황을 반영\n",
    "    A.RandomShadow(p=0.2),\n",
    "\n",
    "    # RGB 채널별 색상 이동: 다양한 카메라 환경, 화이트밸런스 차이 대응\n",
    "    A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.2),\n",
    "\n",
    "    # 이미지 일부분을 무작위로 지우기 (일부 가림 상황을 반영)\n",
    "    A.CoarseDropout(max_holes=2,          # 최대 2개 영역 제거\n",
    "                    max_height=16, \n",
    "                    max_width=16, \n",
    "                    p=0.3),\n",
    "\n",
    "    # 픽셀값을 정규화 (ImageNet 사전학습 모델 기준 평균/표준편차)\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "    # numpy 이미지 → PyTorch Tensor 변환\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 수: 33137\n",
      "train 이미지 수: 26509, valid 이미지 수: 6628\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋 로드\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "print(f\"총 이미지 수: {len(full_dataset)}\")\n",
    "\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "# Stratified Split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "# Subset + transform 각각 적용\n",
    "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
    "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
    "print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n",
    "\n",
    "\n",
    "# DataLoader 정의\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=True)  # ResNet18 모델 불러오기\n",
    "        self.feature_dim = self.backbone.fc.in_features \n",
    "        self.backbone.fc = nn.Identity()  # feature extractor로만 사용\n",
    "        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)       \n",
    "        x = self.head(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[Epoch 1/10] Training: 100%|██████████| 415/415 [04:19<00:00,  1.60it/s]\n",
      "[Epoch 1/10] Validation: 100%|██████████| 104/104 [00:41<00:00,  2.53it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 4.6025 || Valid Loss : 2.7474 | Valid Accuracy : 58.3283%\n",
      "📦 Best model saved at epoch 1 (logloss: 2.7463)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2/10] Training: 100%|██████████| 415/415 [04:44<00:00,  1.46it/s]\n",
      "[Epoch 2/10] Validation: 100%|██████████| 104/104 [00:41<00:00,  2.52it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 1.9825 || Valid Loss : 1.0552 | Valid Accuracy : 81.6083%\n",
      "📦 Best model saved at epoch 2 (logloss: 1.0550)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3/10] Training: 100%|██████████| 415/415 [04:34<00:00,  1.51it/s]\n",
      "[Epoch 3/10] Validation: 100%|██████████| 104/104 [00:35<00:00,  2.93it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.8596 || Valid Loss : 0.5862 | Valid Accuracy : 88.2317%\n",
      "📦 Best model saved at epoch 3 (logloss: 0.5864)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4/10] Training: 100%|██████████| 415/415 [04:20<00:00,  1.59it/s]\n",
      "[Epoch 4/10] Validation: 100%|██████████| 104/104 [00:34<00:00,  2.99it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.4807 || Valid Loss : 0.3893 | Valid Accuracy : 90.8117%\n",
      "📦 Best model saved at epoch 4 (logloss: 0.3892)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5/10] Training: 100%|██████████| 415/415 [04:20<00:00,  1.59it/s]\n",
      "[Epoch 5/10] Validation: 100%|██████████| 104/104 [00:34<00:00,  2.99it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.3137 || Valid Loss : 0.2958 | Valid Accuracy : 92.1696%\n",
      "📦 Best model saved at epoch 5 (logloss: 0.2957)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6/10] Training: 100%|██████████| 415/415 [04:19<00:00,  1.60it/s]\n",
      "[Epoch 6/10] Validation: 100%|██████████| 104/104 [00:34<00:00,  2.99it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.2280 || Valid Loss : 0.2513 | Valid Accuracy : 92.7731%\n",
      "📦 Best model saved at epoch 6 (logloss: 0.2517)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7/10] Training: 100%|██████████| 415/415 [04:20<00:00,  1.60it/s]\n",
      "[Epoch 7/10] Validation: 100%|██████████| 104/104 [00:34<00:00,  2.98it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1701 || Valid Loss : 0.2405 | Valid Accuracy : 93.1804%\n",
      "📦 Best model saved at epoch 7 (logloss: 0.2408)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8/10] Training: 100%|██████████| 415/415 [25:28<00:00,  3.68s/it]    \n",
      "[Epoch 8/10] Validation: 100%|██████████| 104/104 [00:42<00:00,  2.42it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1421 || Valid Loss : 0.2231 | Valid Accuracy : 93.5124%\n",
      "📦 Best model saved at epoch 8 (logloss: 0.2235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] Training: 100%|██████████| 415/415 [04:35<00:00,  1.51it/s]\n",
      "[Epoch 9/10] Validation: 100%|██████████| 104/104 [00:36<00:00,  2.87it/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1219 || Valid Loss : 0.2125 | Valid Accuracy : 94.1008%\n",
      "📦 Best model saved at epoch 9 (logloss: 0.2126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10/10] Training: 100%|██████████| 415/415 [04:20<00:00,  1.59it/s]\n",
      "[Epoch 10/10] Validation: 100%|██████████| 104/104 [00:35<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.1082 || Valid Loss : 0.1944 | Valid Accuracy : 94.1762%\n",
      "📦 Best model saved at epoch 10 (logloss: 0.1948)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BaseModel(num_classes=len(class_names)).to(device)\n",
    "best_logloss = float('inf')\n",
    "# 추가: Early Stopping을 위한 변수\n",
    "patience = 5  # 개선 없을 때 몇 epoch까지 기다릴지\n",
    "counter = 0   # 현재까지 개선되지 않은 횟수\n",
    "\n",
    "# 손실 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "\n",
    "# 학습 및 검증 루프\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # LogLoss\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n",
    "\n",
    "    # Best model 저장\n",
    "    if val_logloss < best_logloss:\n",
    "        best_logloss = val_logloss\n",
    "        torch.save(model.state_dict(), f'best_model.pth')\n",
    "        print(f\"📦 Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")\n",
    "        counter = 0  # 성능 개선되었으므로 초기화\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"⚠️ No improvement for {counter} epoch(s).\")\n",
    "        if counter >= patience:\n",
    "            print(f\"⏹ Early stopping triggered at epoch {epoch+1}\")\n",
    "            break  # 학습 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\miniconda3\\envs\\HAI\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 로드\n",
    "model = BaseModel(num_classes=len(class_names))\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "# 추론\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "        # 각 배치의 확률을 리스트로 변환\n",
    "        for prob in probs.cpu():  # prob: (num_classes,)\n",
    "            result = {\n",
    "                class_names[i]: prob[i].item()\n",
    "                for i in range(len(class_names))\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "pred = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./result/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('./result/submission_02.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
